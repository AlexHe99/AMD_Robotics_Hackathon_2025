{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQUk3Y0WwYZ4"
   },
   "source": [
    "# Train Models Using LeRobot on MI300x\n",
    "\n",
    "This guide walks you through setting up environment for training imitation learning policies using LeRobot library on a DigitalOcean (DO) instance equipped with AMD MI300x GPUs and ROCm.\n",
    "\n",
    "## ⚙️ Requirements\n",
    "- A Hugging Face dataset repo ID containing your training data (`--dataset.repo_id=${HF_USER}/${DATASET_NAME}`).\n",
    "  If you don’t have an access token yet, you can sign up for Hugging Face [here](https://huggingface.co/join). After signing up, create an access token by visiting [here](https://huggingface.co/settings/tokens).\n",
    "- A wandb account to enable training visualization and upload your training evidence to our github.\n",
    "  You can sign up for Wandb [here](https://wandb.ai/signup) and visit [here](https://wandb.ai/authorize) to create a token.\n",
    "- Access to DO instance AMD Mi300x GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOJyX0CnwA5m"
   },
   "source": [
    "## Verify ROCm and GPU availability\n",
    "This cell uses `pytorch` to check AMD GPU Info. The expected ouput is \n",
    "```\n",
    "CUDA compatible device availability: True\n",
    "device name [0]: AMD Instinct MI300X VF\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'CUDA compatible device availability:',torch.cuda.is_available())\n",
    "print(f'device name [0]:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOJyX0CnwA5m"
   },
   "source": [
    "## Install FFmpeg 7.x\n",
    "This cell uses `apt` to install ffmpeg 7.x for LeRobot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlKjL1X5t_zM",
    "outputId": "3b375aa1-19ed-4811-ff76-0afd5b762992"
   },
   "outputs": [],
   "source": [
    "!add-apt-repository ppa:ubuntuhandbook1/ffmpeg7 -y # install PPA which contains ffmpeg 7.x\n",
    "!apt update && apt install ffmpeg -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxCc3CARwUjN"
   },
   "source": [
    "## Install LeRobot v0.4.0\n",
    "This cell clones the `lerobot` repository from Hugging Face, and installs the package in editable mode. Extra Features: To install additional dependencies for training SmolVLA or Pi models, refer to the [LeRobot offical page](https://huggingface.co/docs/lerobot/index). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgLu7QT5tUik",
    "outputId": "e46913b8-1977-48a5-a851-d8c69602419a"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/lerobot.git\n",
    "!cd lerobot && git checkout -b v0.4.0 v0.4.0 # let’s synchronize using this version\n",
    "!cd lerobot && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Sn2wG4wldo"
   },
   "source": [
    "## Weights & Biases login\n",
    "This cell install and log into Weights & Biases (wandb) to enable experiment tracking and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PolVM_movEvp",
    "outputId": "1769c6bd-8644-4b65-84c7-4f020b234c92"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!wandb login # enter your token to login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkzTo4mNwxaC"
   },
   "source": [
    "## Start training Models with LeRobot\n",
    "\n",
    "This cell uses the lerobot-train CLI from the lerobot library to train a robot control policy.  \n",
    "\n",
    "Make sure to adjust the following arguments to your setup:\n",
    "\n",
    "1. `--dataset.repo_id=YOUR_HF_USERNAME/YOUR_DATASET`:  \n",
    "   Replace this with the Hugging Face Hub repo ID where your dataset is stored, e.g., `lerobot/svla_so100_pickplace`.\n",
    "\n",
    "2. `--policy.type=act`:  \n",
    "   Specifies the policy configuration to use. `act` refers to [configuration_act.py](../lerobot/common/policies/act/configuration_act.py), which will automatically adapt to your dataset’s setup (e.g., number of motors and cameras).\n",
    "\n",
    "3. `--output_dir=outputs/train/...`:  \n",
    "   Directory where training logs and model checkpoints will be saved.\n",
    "\n",
    "4. `--job_name=...`:  \n",
    "   A name for this training job, used for logging and Weights & Biases.The name typically includes the model type (e.g., act, smolvla), the dataset name, and additional descriptive tags.\n",
    "\n",
    "5. `--policy.device=cuda`:  \n",
    "   Use `cuda` if training on an AMD or NVIDIA GPU. \n",
    "\n",
    "6. `--wandb.enable=true`:  \n",
    "   Enables Weights & Biases for visualizing training progress. You must be logged in via `wandb login` before running this.\n",
    "\n",
    "7. `--policy.push_to_hub=`:\n",
    "\n",
    "   Enables automatic uploading of the trained policy to the Hugging Face Hub. You must specify `--policy.repo_id` (e.g., ${HF_USER}/{REPO_NAME}) if it is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ufss6US6xbpi",
    "outputId": "cfd494c7-8689-419d-bb17-7f02a67b26d6"
   },
   "outputs": [],
   "source": [
    "!lerobot-train \\\n",
    "  --dataset.repo_id=${HF_USER}/${DATASET_NAME} \\\n",
    "  --batch_size=128 \\\n",
    "  --steps=10000 \\\n",
    "  --output_dir=outputs/train/act_so101_3cube_10ksteps \\ \n",
    "  --job_name=act_so101_3cube_10ksteps \\\n",
    "  --policy.device=cuda \\\n",
    "  --policy.type=act \\ # change to other models:smolvla, Pi0, Pi05\n",
    "  --policy.push_to_hub=false \\\n",
    "  --wandb.enable=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "\n",
    "- If using a local dataset, add `--dataset.root=/path/to/dataset`.\n",
    "- Adjust `--batch_size` and `--steps` based on your hardware and dataset.\n",
    "- Model checkpoints, logs, and training plots will be saved to the specified `--output_dir`\n",
    "- Training progress visualized in your wandb dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login into Hugging Face Hub\n",
    "Now after training is done login into the Hugging Face hub and upload the last checkpoint. You may refer to [here](https://github.com/huggingface/lerobot/blob/v0.4.0/README.md#add-a-pretrained-policy) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yu5khQGIHi6",
    "outputId": "a8452719-c53e-450b-9344-b088b296815e"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFMLGuVkH7UN",
    "outputId": "535f0717-4d6b-4eeb-beee-25416f7af383"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli upload ${HF_USER}/{REPO_NAME} path/to/pretrained_model\n",
    "# e.g. huggingface-cli upload ${HF_USER}/act_so101_3cube_10ksteps \\\n",
    "#  /lerobot/outputs/train/act_so101_3cube_10ksteps/checkpoints/last/pretrained_model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
